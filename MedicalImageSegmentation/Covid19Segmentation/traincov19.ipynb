{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# uGAN2D_cov19_lungles\n* filtre = 8\n* 2 channels\n* n_patch = 6\n* lr = dynamic\n* alpha = 5","metadata":{"papermill":{"duration":0.060512,"end_time":"2022-05-12T08:24:00.757203","exception":false,"start_time":"2022-05-12T08:24:00.696691","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# IMPORTS & INSTALL","metadata":{"id":"AU3qukrZJUP0","papermill":{"duration":0.037791,"end_time":"2022-05-12T08:24:00.860056","exception":false,"start_time":"2022-05-12T08:24:00.822265","status":"completed"},"tags":[]}},{"cell_type":"code","source":"! pip install elasticdeform\n! pip install tensorflow_addons\n! pip install gdown\n","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:00.944122Z","iopub.status.busy":"2022-05-12T08:24:00.943644Z","iopub.status.idle":"2022-05-12T08:24:46.989731Z","shell.execute_reply":"2022-05-12T08:24:46.988866Z"},"papermill":{"duration":46.088477,"end_time":"2022-05-12T08:24:46.992200","exception":false,"start_time":"2022-05-12T08:24:00.903723","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\ninputs_file = 'https://drive.google.com/file/d/1-XPgETUZYwspdQBaiNk7K7XR7yeyYgcA/view?usp=sharing'\ninputs_url = 'https://drive.google.com/uc?id=1-XPgETUZYwspdQBaiNk7K7XR7yeyYgcA'\n\ninputs_output = 'inputs.zip'\n\ngdown.download(inputs_url, inputs_output, quiet=False)","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:47.096889Z","iopub.status.busy":"2022-05-12T08:24:47.096171Z","iopub.status.idle":"2022-05-12T08:24:48.558077Z","shell.execute_reply":"2022-05-12T08:24:48.557090Z"},"papermill":{"duration":1.516733,"end_time":"2022-05-12T08:24:48.560265","exception":false,"start_time":"2022-05-12T08:24:47.043532","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip ./inputs.zip -d ./INPUTS\n! mv -v ./INPUTS/content/drive/MyDrive/GANs/CovidLesionDetection/INPUTS/* ./INPUTS\n! rm -rf ./INPUTS/content\n! rm ./inputs.zip","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:48.666625Z","iopub.status.busy":"2022-05-12T08:24:48.665924Z","iopub.status.idle":"2022-05-12T08:24:51.328403Z","shell.execute_reply":"2022-05-12T08:24:51.327438Z"},"papermill":{"duration":2.717892,"end_time":"2022-05-12T08:24:51.330386","exception":false,"start_time":"2022-05-12T08:24:48.612494","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXEC = 6\n\nVERSION = 'uGAN2D_cov19_lungles'\n\nINPUT_PATH = './INPUTS'\n\nPATH = './RESULTS' \n\nDATA_PATH = './data'","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:51.441009Z","iopub.status.busy":"2022-05-12T08:24:51.440734Z","iopub.status.idle":"2022-05-12T08:24:51.445070Z","shell.execute_reply":"2022-05-12T08:24:51.444403Z"},"papermill":{"duration":0.060861,"end_time":"2022-05-12T08:24:51.446781","exception":false,"start_time":"2022-05-12T08:24:51.385920","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EXEC!=1:\n    results_file = 'https://drive.google.com/file/d/156AkeU7wx1n4vmcYZ30ulCeaY0Nmq8V0/view?usp=sharing'\n    results_url = 'https://drive.google.com/uc?id=156AkeU7wx1n4vmcYZ30ulCeaY0Nmq8V0'\n\n    results_output = 'results.zip'\n\n    gdown.download(results_url, results_output, quiet=False)\n    \nelse:\n    ! mkdir ./RESULTS","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:51.555802Z","iopub.status.busy":"2022-05-12T08:24:51.555278Z","iopub.status.idle":"2022-05-12T08:24:53.215104Z","shell.execute_reply":"2022-05-12T08:24:53.213833Z"},"papermill":{"duration":1.716887,"end_time":"2022-05-12T08:24:53.217670","exception":false,"start_time":"2022-05-12T08:24:51.500783","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EXEC!=1:\n    ! unzip ./results.zip -d ./RESULTS\n    ! mv -v ./RESULTS/content/drive/MyDrive/GANs/CovidLesionDetection/RESULTS_KAGGLE/VERSION_$VERSION/RESULTS_{EXEC-1}/* ./RESULTS\n    ! rm -rf ./RESULTS/content\n    ! rm ./results.zip  ","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:53.331881Z","iopub.status.busy":"2022-05-12T08:24:53.331187Z","iopub.status.idle":"2022-05-12T08:24:56.622445Z","shell.execute_reply":"2022-05-12T08:24:56.621389Z"},"papermill":{"duration":3.350555,"end_time":"2022-05-12T08:24:56.624945","exception":false,"start_time":"2022-05-12T08:24:53.274390","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn\nimport cv2 as cv\nimport nibabel as nib\nimport pickle\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nimport tqdm\nimport gc\nimport warnings\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras import losses, metrics\nfrom keras import optimizers\nfrom keras import callbacks\nfrom keras.models import Model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers import concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\nfrom keras.layers import Multiply\n\nimport math\nfrom functools import reduce\nimport glob\nimport time\nimport os \nfrom tensorflow.keras.utils import to_categorical\nfrom sys import stdout\nfrom scipy.ndimage.interpolation import affine_transform\nfrom sklearn.model_selection import train_test_split\nimport elasticdeform\nimport matplotlib.image as mpim\nimport multiprocessing as mp\nimport json","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:24:56.756054Z","iopub.status.busy":"2022-05-12T08:24:56.755518Z","iopub.status.idle":"2022-05-12T08:25:04.569178Z","shell.execute_reply":"2022-05-12T08:25:04.568400Z"},"id":"PMAGSZ9K3BlD","papermill":{"duration":7.88108,"end_time":"2022-05-12T08:25:04.571407","exception":false,"start_time":"2022-05-12T08:24:56.690327","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metadata = pd.read_csv('/content/drive/MyDrive/COVID19_Dataset/metadata.csv')\n# # metadata.replace('../input/covid19-ct-scans/', '', regex=True, inplace=True)\n# print(metadata.shape)\n# metadata.head()","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:04.689122Z","iopub.status.busy":"2022-05-12T08:25:04.688573Z","iopub.status.idle":"2022-05-12T08:25:04.692091Z","shell.execute_reply":"2022-05-12T08:25:04.691389Z"},"id":"xbUqbHEH3XSf","papermill":{"duration":0.064509,"end_time":"2022-05-12T08:25:04.693938","exception":false,"start_time":"2022-05-12T08:25:04.629429","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PATCH EXTRACTION AND AUGMENTATION","metadata":{"id":"h5jomFTiInBM","papermill":{"duration":0.056725,"end_time":"2022-05-12T08:25:04.807567","exception":false,"start_time":"2022-05-12T08:25:04.750842","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#PATCH EXTRACTION AND AUGMENTATION technique\n\ndef patch_extraction(Xb, yb, PatchesShape=(128,128,32), Npatches=1, max_tries = 1000, background_threshold=0.95, num_classes=4, apply_ratio=False):\n    \"\"\"\n    3D patch extraction\n    \"\"\"\n    \n    batch_size = len(Xb)\n    X_patches = np.empty((batch_size*Npatches, PatchesShape[0], PatchesShape[1], PatchesShape[2]))\n    y_patches = np.empty((batch_size*Npatches, PatchesShape[0], PatchesShape[1], PatchesShape[2]))\n    i = 0\n    \n    if apply_ratio:\n#       print(f'Application of ratio(bg_ratio < {background_threshold*100}%): {apply_ratio}')\n      for b in range(batch_size):\n          Xb_temp = Xb[b]\n          yb_temp = yb[b]\n          rows, columns, slices= Xb_temp.shape\n          for p in range(Npatches):\n              \n              temp_X = None\n              temp_y = None\n\n              tries = 0\n              out = False    \n              inf = 1\n\n              while (tries < max_tries) and (not out):\n                \n                x = np.random.randint(rows-PatchesShape[0]+1) \n                y = np.random.randint(columns-PatchesShape[1]+1)\n                z = np.random.randint(slices-PatchesShape[2]+1)  \n\n                \n                temp_X = Xb_temp[x:x+PatchesShape[0], y:y+PatchesShape[1], z:z+PatchesShape[2]]\n               \n                temp_y = yb_temp[x:x+PatchesShape[0], y:y+PatchesShape[1], z:z+PatchesShape[2]]\n\n                \n                bgrd_ratio = 1 - np.sum(temp_y[temp_y!=0])/(PatchesShape[0] * PatchesShape[1] * PatchesShape[2])\n                bgrd_ratio_off = bgrd_ratio\n\n                if bgrd_ratio <= inf :\n                  temp_x_min = temp_X\n                  temp_y_min = temp_y\n                  inf = bgrd_ratio\n                  \n                tries += 1\n\n                if bgrd_ratio < background_threshold:\n                  out = True\n                  temp_X = Xb_temp[x:x+PatchesShape[0], y:y+PatchesShape[1], z:z+PatchesShape[2]]\n                else :\n                  temp_X = temp_x_min\n                  temp_y = temp_y_min\n                  bgrd_ratio_off = inf\n                \n#               print(f'\\nBG_ratio : {bgrd_ratio_off*100} % for index {i}')\n#               print(f\"\\nTried {tries} times to find a sub-volume. Exit...\")\n              X_patches[i] = temp_X\n              y_patches[i] = temp_y\n              i += 1\n      \n      del Xb_temp, yb_temp, temp_X, temp_y,temp_x_min,temp_y_min\n    \n    else:\n      for b in range(batch_size):\n        Xb_temp = Xb[b]\n        yb_temp = yb[b]\n        rows, columns, slices= Xb_temp.shape\n        \n        if rows < PatchesShape[0]:\n            if (rows%2)!=0:\n                rows = rows-1\n            \n            new_frame_X = np.empty((PatchesShape[0],columns,slices))\n            new_frame_y = np.empty((PatchesShape[0],columns,slices))\n            \n            for slc in range(slices):\n                slicee_X = Xb_temp[:,:,slc]\n                slicee_y = yb_temp[:,:,slc]\n                \n                for c in range(columns):\n                    column_X = slicee_X[:,c]\n                    column_y = slicee_y[:,c]\n                    pad_arr_X = np.pad(column_X[:-1], (((PatchesShape[0]-rows)//2),), 'constant', constant_values=(0, 0))\n                    pad_arr_y = np.pad(column_y[:-1], (((PatchesShape[0]-rows)//2),), 'constant', constant_values=(0, 0))\n\n                    new_frame_X[:,c,slc] = pad_arr_X\n                    new_frame_y[:,c,slc] = pad_arr_y\n            \n            Xb_temp = new_frame_X\n            yb_temp = new_frame_y\n        \n        if columns < PatchesShape[1]:\n            if (columns%2)!=0:\n                columns = columns-1\n            \n            new_frame_X = np.empty((rows,PatchesShape[1],slices))\n            new_frame_y = np.empty((rows,PatchesShape[1],slices))\n            \n            for slc in range(slices):\n                slicee_X = Xb_temp_X[:,:,slc]\n                slicee_y = yb_temp[:,:,slc]\n                \n                for r in range(rows):\n                    row_X = slicee_X[r,:]\n                    row_y = slicee_y[r,:]\n                    pad_arr_X = np.pad(row_X[:-1], (((PatchesShape[1]-columns)//2),), 'constant', constant_values=(0, 0))\n                    pad_arr_y = np.pad(row_y[:-1], (((PatchesShape[1]-columns)//2),), 'constant', constant_values=(0, 0))\n                    new_frame_X[r,:,slc] = pad_arr_X\n                    new_frame_y[r,:,slc] = pad_arr_y\n            \n            Xb_temp = new_frame_X\n            yb_temp = new_frame_y\n        \n        for p in range(Npatches):\n\n            rows, columns, slices= Xb_temp.shape\n            x = np.random.randint(rows-PatchesShape[0]+1) \n            y = np.random.randint(columns-PatchesShape[1]+1)\n            z = np.random.randint(slices-PatchesShape[2]+1)  \n\n            X_patches[i] = Xb_temp[x:x+PatchesShape[0], y:y+PatchesShape[1], z:z+PatchesShape[2]]\n            y_patches[i] = yb_temp[x:x+PatchesShape[0], y:y+PatchesShape[1], z:z+PatchesShape[2]]\n            i += 1\n      \n      del Xb_temp, yb_temp\n\n    return X_patches, y_patches\n\n\n\ndef flip3D(X, y):\n    \"\"\"\n    Flip the 3D image respect one of the 3 axis chosen randomly\n    \"\"\"\n    choice = np.random.randint(3)\n    if choice == 0: # flip on x\n        X_flip, y_flip = X[::-1, :, :], y[::-1, :, :]\n    if choice == 1: # flip on y\n        X_flip, y_flip = X[:, ::-1, :], y[:, ::-1, :]\n    if choice == 2: # flip on z\n        X_flip, y_flip = X[:, :, ::-1], y[:, :, ::-1]\n        \n    return X_flip, y_flip\n\n\ndef rotation3D(X, y):\n    \"\"\"\n    Rotate a 3D image with alfa, beta and gamma degree respect the axis x, y and z respectively.\n    The three angles are chosen randomly between 0-30 degrees\n    \"\"\"\n    alpha, beta, gamma = np.pi*np.random.random_sample(3,)/6\n    Rx = np.array([[1, 0, 0],\n                   [0, np.cos(alpha), -np.sin(alpha)],\n                   [0, np.sin(alpha), np.cos(alpha)]])\n    \n    Ry = np.array([[np.cos(beta), 0, np.sin(beta)],\n                   [0, 1, 0],\n                   [-np.sin(beta), 0, np.cos(beta)]])\n    \n    Rz = np.array([[np.cos(gamma), -np.sin(gamma), 0],\n                   [np.sin(gamma), np.cos(gamma), 0],\n                   [0, 0, 1]])\n    \n    R = np.dot(np.dot(Rx, Ry), Rz)\n    \n    X_rot = np.empty_like(X)\n    X_rot[:,:,:] = affine_transform(X[:,:,:], R, offset=0, order=3, mode='constant')\n    y_rot = affine_transform(y, R, offset=0, order=0, mode='constant')\n    \n    return X_rot, y_rot\n\ndef brightness(X, y):\n    \"\"\"\n    Changing the brighness of a image using power-law gamma transformation.\n    Gain and gamma are chosen randomly for each image channel.\n    \n    Gain chosen between [0.9 - 1.1]\n    Gamma chosen between [0.9 - 1.1]\n    \n    new_im = gain * im^gamma\n    \"\"\"\n    \n    X_new = np.zeros(X.shape)\n    im = X[:,:,:]        \n    gain, gamma = (1.2 - 0.8) * np.random.random_sample(2,) + 0.8\n    im_new = np.sign(im)*gain*(np.abs(im)**gamma)\n    X_new[:,:,:] = im_new \n    \n    del im,im_new\n\n    return X_new, y\n\ndef elastic(X, y):\n    \"\"\"\n    Elastic deformation on a image and its target\n    \"\"\"  \n    [Xel, yel] = elasticdeform.deform_random_grid([X, y], sigma=2, axis=[(0, 1, 2), (0, 1, 2)], order=[1, 0], mode='constant')\n    \n    return Xel, yel\n\ndef random_decisions(N):\n    \"\"\"\n    Generate N random decisions for augmentation\n    N should be equal to the batch size\n    \"\"\"\n    \n    decisions = np.zeros((N, 4)) # 4 is number of aug techniques to combine (patch extraction excluded)\n    for n in range(N):\n        decisions[n] = np.random.randint(2, size=4)\n        \n    return decisions\n\ndef combine_aug(X, y, do):\n    \"\"\"\n    Combine randomly the different augmentation techniques written above\n    \"\"\"\n    Xnew, ynew = X, y\n    \n    # make sure to use at least the 25% of original images\n    if np.random.random_sample()>0.75:\n        return Xnew, ynew\n    \n    else:   \n        if do[0] == 1:\n#             Xnew, ynew = flip3D(Xnew, ynew)\n            Xnew, ynew = elastic(Xnew, ynew)\n\n        if do[1] == 1:\n#             Xnew, ynew = brightness(Xnew, ynew)\n            Xnew, ynew = elastic(Xnew, ynew)\n\n        if do[2] == 1:\n#             Xnew, ynew = rotation3D(Xnew, ynew)\n#             Xnew, ynew = flip3D(Xnew, ynew)\n            Xnew, ynew = elastic(Xnew, ynew)\n\n        if do[3] == 1:\n            Xnew, ynew = elastic(Xnew, ynew)\n        \n        return Xnew, ynew\n\ndef aug_batch(Xb, Yb):\n    \"\"\"\n    Generate a augmented image batch \n    \"\"\"\n    batch_size = len(Xb)\n    newXb, newYb = np.empty_like(Xb), np.empty_like(Yb)\n    \n    decisions = random_decisions(batch_size)            \n    inputs = [(X, y, do) for X, y, do in zip(Xb, Yb, decisions)]\n    pool = mp.Pool(processes=8)\n    multi_result = pool.starmap(combine_aug, inputs)\n    pool.close()\n    \n    for i in range(len(Xb)):\n        newXb[i], newYb[i] = multi_result[i][0], multi_result[i][1]\n\n    del inputs,decisions   \n    return newXb, newYb ","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:04.923793Z","iopub.status.busy":"2022-05-12T08:25:04.923499Z","iopub.status.idle":"2022-05-12T08:25:04.971291Z","shell.execute_reply":"2022-05-12T08:25:04.970610Z"},"id":"ZiWhAKzR-4SS","papermill":{"duration":0.108451,"end_time":"2022-05-12T08:25:04.973429","exception":false,"start_time":"2022-05-12T08:25:04.864978","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD DATA","metadata":{"id":"kDMdpWzDIun8","papermill":{"duration":0.057937,"end_time":"2022-05-12T08:25:05.089250","exception":false,"start_time":"2022-05-12T08:25:05.031313","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#load les imags et appliquer les augmentation\n\ndef load_img(img_files):\n    ''' Load one image and its target form file\n    '''\n    N = len(img_files)\n    # target\n    y = nib.load(img_files[N-1]).get_fdata(dtype='float32', caching='unchanged')\n    y[y==2]=1\n    y[y==3]=1\n    \n    # y = y[0:630,130:590,0:35] #(630,460,35)\n    y_les = nib.load(img_files[1]).get_fdata(dtype='float32', caching='unchanged')\n    \n    \n    X_norm = np.empty(y.shape)\n\n    X = nib.load(img_files[0]).get_fdata(dtype='float32', caching='unchanged')\n    # X = X[0:630,130:590,0:35] \n    X = X*y\n    lung = X[X!=0] \n    lung_norm = np.zeros_like(X) # background at -100\n\n    \n    xmax, xmin = np.max(lung), np.min(lung)\n    lung_norm[X!=0]  = (lung - xmin)/(xmax - xmin)\n    \n    X_norm[:,:,:] = lung_norm        \n            \n    del(X, lung, lung_norm)\n    \n    X_norm = np.rot90(np.array(X_norm))\n    y = np.rot90(np.array(y))\n    y_les = np.rot90(np.array(y_les))\n    \n    return X_norm, y_les\n    \n    \nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, batch_size=4, n_channels=1, n_classes=1, shuffle=True, augmentation=False, patch_shape=(128,128,32), n_patches=1):\n        'Initialization'\n        self.list_IDs = list_IDs\n        self.batch_size = batch_size\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.augmentation = augmentation\n        self.patch_shape = patch_shape\n        self.n_patches = n_patches\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return len(self.list_IDs) // self.batch_size\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data     \n        X, y = self.__data_generation(list_IDs_temp)\n        if self.augmentation == True:\n            X, y = self.__data_augmentation(X, y)\n        \n        if index == self.__len__()-1:\n            self.on_epoch_end()\n        \n        new_X = np.empty((self.batch_size*self.n_patches*self.patch_shape[2], self.patch_shape[0], self.patch_shape[1], 1))\n        new_y = np.empty((self.batch_size*self.n_patches*self.patch_shape[2], self.patch_shape[0], self.patch_shape[1], 2))\n        \n        p = 0\n        for n in range(len(X)):\n            Xb = X[n,:,:,:,:]\n            yb = y[n,:,:,:,:]\n            \n            for i in range(Xb.shape[2]):\n                new_X[p,:,:,:]= Xb[:,:,i,:]\n                new_y[p,:,:,:]= yb[:,:,i,:]\n                p = p+1\n        \n        del X,y,Xb,yb\n        return new_X, new_y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n  \n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' \n        # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = []\n        y = []\n        for i, IDs in enumerate(list_IDs_temp):\n          \n          X_temp, y_temp = load_img(IDs)\n          X.insert(i,X_temp)\n          y.insert(i,y_temp)\n        \n        del X_temp, y_temp\n\n        return X, y\n        \n    def __data_augmentation(self, X, y):\n        'Apply augmentation'\n        X_p, y_p = patch_extraction(X, y, PatchesShape=self.patch_shape, Npatches=self.n_patches)\n        \n        X_augg, y_augg = aug_batch(X_p, y_p)\n        \n        X_aug = np.empty(X_augg.shape)\n        y_aug = np.empty(y_augg.shape)\n\n        for b in range(len(y_aug)):\n          y1 = y_augg[b,:]\n          y2 = y_p[b,:]\n          \n          bgrd_ratio_after_aug = 1 - np.sum(y1[y1!=0])/(self.patch_shape[0] * self.patch_shape[1] * self.patch_shape[2])\n          bgrd_ratio_before_aug = 1 - np.sum(y2[y2!=0])/(self.patch_shape[0] * self.patch_shape[1] * self.patch_shape[2])\n\n          if (bgrd_ratio_after_aug > bgrd_ratio_before_aug) and (False):\n            print(f'Index : {b} - Bg_ratio_BEFORE : {bgrd_ratio_before_aug} <<< Bg_ratio_AFTER : {bgrd_ratio_after_aug} ==> Drop augmentation.')\n            X_aug[b,:] = X_p[b,:]\n            y_aug[b,:] = y_p[b,:]\n          else:\n            X_aug[b,:] = X_augg[b,:]\n            y_aug[b,:] = y_augg[b,:]\n\n\n        X_new_shape = np.empty((self.batch_size*self.n_patches, *(self.patch_shape), 1))\n        \n\n        for n in range(len(X_aug)):\n          image_data = X_aug[n,:,:,:]\n          neww1 = np.zeros(image_data.shape)\n#           neww2 = np.zeros(image_data.shape)\n          for i in range(len(image_data[0,0,:])):\n            slicee = image_data[:,:,i]\n            slicee = np.uint8(slicee*255) \n            clahe1 = cv.createCLAHE(clipLimit=3.0)\n            clahe_img1 = clahe1.apply(slicee)\n            neww1[:,:,i]= clahe_img1\n\n            \n          X_new_shape[n,:,:,:,0] = neww1\n        \n        del X_aug,X_augg,y_augg,X_p,y_p,y1,y2,image_data,neww1,slicee,clahe_img1\n\n        return X_new_shape.astype('float32'), to_categorical(y_aug).astype('float32')","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:05.204975Z","iopub.status.busy":"2022-05-12T08:25:05.204726Z","iopub.status.idle":"2022-05-12T08:25:05.233612Z","shell.execute_reply":"2022-05-12T08:25:05.232908Z"},"id":"6ojwzkF_AR3x","papermill":{"duration":0.089243,"end_time":"2022-05-12T08:25:05.235245","exception":false,"start_time":"2022-05-12T08:25:05.146002","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL\n","metadata":{"id":"zGp2f21DjxPP","papermill":{"duration":0.056688,"end_time":"2022-05-12T08:25:05.348753","exception":false,"start_time":"2022-05-12T08:25:05.292065","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Conv3D, Conv2D, Conv3DTranspose, Dropout, ReLU, LeakyReLU, Concatenate, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import MeanSquaredError\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.layers import InstanceNormalization\nfrom tensorflow.keras.layers import BatchNormalization","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:05.464052Z","iopub.status.busy":"2022-05-12T08:25:05.463510Z","iopub.status.idle":"2022-05-12T08:25:05.593767Z","shell.execute_reply":"2022-05-12T08:25:05.593010Z"},"id":"yHF79hBnj-Kv","papermill":{"duration":0.190317,"end_time":"2022-05-12T08:25:05.595968","exception":false,"start_time":"2022-05-12T08:25:05.405651","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MODELS Unet3DGan\ndef double_conv(layer, Nf, ks, norm=True):\n      x=layer\n      del layer\n      for ss in range(2):\n          x = Conv2D(Nf, kernel_size=ks, strides=1, kernel_initializer='he_normal', padding='same')(x)\n          \n          #a chaque etape effectuer la convolution afin d obtenir shape/2 avec nombre de filtre comme 4 eme D\n          if (norm):\n              x = BatchNormalization()(x) #Normaliser l image seulement \n          x = ReLU()(x) #Activer la sortie\n      return x   \n\ndef Generator():\n    '''\n    Generator model\n    '''\n    \n    def encoder_step(layer, Nf, ks, norm=True):\n        x = double_conv(layer, Nf/2, ks, norm)\n        del layer\n        x = Conv2D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(x)  \n        x = Dropout(0.1)(x)\n\n        return x\n\n    def bottlenek(layer, Nf, ks):\n        x = Conv2D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n        x = BatchNormalization()(x)\n        x = ReLU()(x)\n        \n        for i in range(4):\n            y = Conv2D(Nf, kernel_size=ks, strides=1, kernel_initializer='he_normal', padding='same')(x)\n            x = BatchNormalization()(y)\n            x = ReLU()(x)\n            x = Concatenate()([x, y])\n#             print(x.shape)\n        return x\n\n    def decoder_step(layer, layer_to_concatenate, Nf, ks):\n        x = Dropout(0.1)(layer)\n        del layer\n        x = Conv2DTranspose(Nf, kernel_size=ks, strides=2, padding='same', kernel_initializer='he_normal')(x)\n        x = Concatenate()([x, layer_to_concatenate])\n        x = double_conv(x, Nf, ks)\n        return x\n\n    layers_to_concatenate = []\n    inputs = Input((512,512,1), name='input_image')\n    Nfilter_start = 24\n    depth = 5\n    ks = 3\n    x = inputs\n\n    # encoder\n    for d in range(depth):\n        if d==0: \n            x = Conv2D(Nfilter_start, kernel_size=ks, strides=1, kernel_initializer='he_normal', padding='same')(x)\n            x = Conv2D(Nfilter_start, kernel_size=ks, strides=1, kernel_initializer='he_normal', padding='same')(x)\n        else:\n            x = encoder_step(x, Nfilter_start*np.power(2,d), ks)\n        \n        layers_to_concatenate.append(x)\n\n    # bottlenek\n    x = bottlenek(x, Nfilter_start*np.power(2,depth-1), ks)\n    \n    # decoder\n    for d in range(depth-2, -1, -1): \n        x = decoder_step(x, layers_to_concatenate.pop(), Nfilter_start*np.power(2,d), ks)\n    \n    # classifier\n    last = Conv2DTranspose(2, kernel_size=ks, strides=2, padding='same', kernel_initializer='he_normal', activation='softmax', name='output_generator')(x)\n    del layers_to_concatenate,x\n    return Model(inputs=inputs, outputs=last, name='Generator')\n\ndef Discriminator():\n    '''\n    Discriminator model\n    '''\n\n    inputs = Input((512,512,1), name='input_image')\n    targets = Input((512,512,2), name='target_image')\n    Nfilter_start = 24\n    depth = 3\n    ks = 3\n\n    def encoder_step(layer, Nf, norm=True):\n        x = Conv2D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n        if norm:\n            x = InstanceNormalization()(x)\n        x = LeakyReLU()(x)\n        x = Dropout(0.1)(x)\n        \n        return x\n\n    x = Concatenate()([inputs, targets])\n\n    for d in range(depth+1):\n        if d==0:\n            x = encoder_step(x, Nfilter_start*np.power(2,d), False)\n        else:\n            x = encoder_step(x, Nfilter_start*np.power(2,d))\n            \n\n    last = Conv2D(1, ks, strides=1, padding='valid', kernel_initializer='he_normal', name='output_discriminator')(x) \n    \n    del x\n    return Model(inputs=[inputs,targets], outputs=last, name='Discriminator')","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:05.714203Z","iopub.status.busy":"2022-05-12T08:25:05.713941Z","iopub.status.idle":"2022-05-12T08:25:05.737490Z","shell.execute_reply":"2022-05-12T08:25:05.736770Z"},"id":"8FAVyx_MkBl7","papermill":{"duration":0.085574,"end_time":"2022-05-12T08:25:05.739069","exception":false,"start_time":"2022-05-12T08:25:05.653495","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOSSES","metadata":{"id":"63ZjMEHSqZwH","papermill":{"duration":0.057237,"end_time":"2022-05-12T08:25:05.854156","exception":false,"start_time":"2022-05-12T08:25:05.796919","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#METRICS EVALUATING\nimport tensorflow.compat.v1 as tff\nimport numpy as np\nfrom scipy import ndimage\n\ndef lossa(y_true,y_pred):\n    smooth = 1e-5  \n    y_true = tf.convert_to_tensor(y_true)\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.convert_to_tensor(y_pred)\n    y_pred = tf.cast(y_pred, tf.float32)\n    intersection = K.sum(y_true * y_pred, axis=[0,1,2])\n    union = K.sum(y_true, axis=[0,1,2]) + K.sum(y_pred, axis=[0,1,2])\n    dice =1- K.mean((2. * intersection + smooth)/(union + smooth))\n    return dice\n\ndef dice_coef_1(y_true, y_pred):\n   \n    y_true = tf.convert_to_tensor(y_true)\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.convert_to_tensor(y_pred)\n    y_pred = tf.cast(y_pred, tf.float32)\n    class_weights = [1.0,1.0]\n    num = tf.math.reduce_sum(tf.math.multiply(class_weights, tf.math.reduce_sum(tf.math.multiply(y_true, y_pred), axis=[0,1,2])))\n    den = tf.math.reduce_sum(tf.math.multiply(class_weights, tf.math.reduce_sum(tf.math.add(y_true, y_pred), axis=[0,1,2])))+1e-5\n\n    return 1-2*num/den\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = y_true.flatten()\n    y_pred_f = y_pred.flatten()\n    intersection = np.sum(y_true_f * y_pred_f)\n    smooth = 1e-5\n\n    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n\ndef binary_dice3d(s,g):\n    #dice score of two 3D volumes\n    smooth = 1e-5\n    num=np.sum(np.multiply(s, g))\n    denom=s.sum() + g.sum() + smooth\n    \n    return  2.0*num/denom\n\ndef sensitivity (seg,ground): \n    #computs false negative rate\n    smooth = 1e-5\n    num=np.sum(np.multiply(ground, seg))\n    denom=np.sum(ground)+smooth\n    \n    return  num/denom\n\ndef specificity (seg,ground): \n    #computes false positive rate\n    smooth = 1e-5\n    num=np.sum(np.multiply(ground==0, seg ==0))\n    denom=np.sum(ground==0)+smooth\n    \n    return  num/denom\n\ndef border_map(binary_img,neigh):\n    \"\"\"\n    Creates the border for a 3D image\n    \"\"\"\n    binary_map = np.asarray(binary_img, dtype=np.uint8)\n    neigh = neigh\n    west = ndimage.shift(binary_map, [-1, 0,0], order=0)\n    east = ndimage.shift(binary_map, [1, 0,0], order=0)\n    north = ndimage.shift(binary_map, [0, 1,0], order=0)\n    south = ndimage.shift(binary_map, [0, -1,0], order=0)\n    top = ndimage.shift(binary_map, [0, 0, 1], order=0)\n    bottom = ndimage.shift(binary_map, [0, 0, -1], order=0)\n    cumulative = west + east + north + south + top + bottom\n    border = ((cumulative < 6) * binary_map) == 1\n    return border\n\ndef border_distance(ref,seg):\n    \"\"\"\n    This functions determines the map of distance from the borders of the\n    segmentation and the reference and the border maps themselves\n    \"\"\"\n    neigh=8\n    border_ref = border_map(ref,neigh)\n    border_seg = border_map(seg,neigh)\n    oppose_ref = 1 - ref\n    oppose_seg = 1 - seg\n    # euclidean distance transform\n    distance_ref = ndimage.distance_transform_edt(oppose_ref)\n    distance_seg = ndimage.distance_transform_edt(oppose_seg)\n    distance_border_seg = border_ref * distance_seg\n    distance_border_ref = border_seg * distance_ref\n    return distance_border_ref, distance_border_seg#, border_ref, border_seg\n\ndef Hausdorff_distance(ref,seg):\n    \"\"\"\n    This functions calculates the average symmetric distance and the\n    hausdorff distance between a segmentation and a reference image\n    :return: hausdorff distance and average symmetric distance\n    \"\"\"\n    ref_border_dist, seg_border_dist = border_distance(ref,seg)\n    hausdorff_distance = np.max([np.max(ref_border_dist), np.max(seg_border_dist)])\n    return hausdorff_distance","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:05.969801Z","iopub.status.busy":"2022-05-12T08:25:05.969547Z","iopub.status.idle":"2022-05-12T08:25:05.990951Z","shell.execute_reply":"2022-05-12T08:25:05.990254Z"},"id":"nPEKHwWVkK0Q","papermill":{"duration":0.081443,"end_time":"2022-05-12T08:25:05.992595","exception":false,"start_time":"2022-05-12T08:25:05.911152","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calcul losses\n\ndef discriminator_loss(disc_real_output, disc_fake_output):\n    real_loss = tf.math.reduce_mean(tf.math.pow(tf.ones_like(disc_real_output) - disc_real_output, 2))\n    fake_loss = tf.math.reduce_mean(tf.math.pow(tf.zeros_like(disc_fake_output) - disc_fake_output, 2))\n\n    disc_loss = 0.5*(real_loss + fake_loss)\n\n    return disc_loss\n\n\ndef generator_loss(target, gen_output, disc_fake_output, alpha):\n    \n    # generalized dice loss\n    dice_loss = lossa(target, gen_output)\n\n    # disc loss\n    disc_loss = tf.math.reduce_mean(tf.math.pow(tf.ones_like(disc_fake_output) - disc_fake_output, 2))\n       \n    # total loss\n    gen_loss = alpha*dice_loss + disc_loss\n\n    return gen_loss, dice_loss, disc_loss","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:06.109906Z","iopub.status.busy":"2022-05-12T08:25:06.109656Z","iopub.status.idle":"2022-05-12T08:25:06.115920Z","shell.execute_reply":"2022-05-12T08:25:06.115218Z"},"id":"DmW_iTSIkJAO","papermill":{"duration":0.067167,"end_time":"2022-05-12T08:25:06.117529","exception":false,"start_time":"2022-05-12T08:25:06.050362","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN\n","metadata":{"id":"R0GO2Sz8kOSr","papermill":{"duration":0.057759,"end_time":"2022-05-12T08:25:06.232822","exception":false,"start_time":"2022-05-12T08:25:06.175063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\n#Importing tqdm function of tqdm module \nfrom tqdm import tqdm  \nfrom time import sleep \nimport math\nfrom keras import backend as K\n\n\n# Models\nG = Generator()\nD = Discriminator()\n\nif os.path.exists(PATH + f'/{VERSION}_Generator.h5')==True and os.path.exists(PATH + f'/{VERSION}_Discriminator.h5')==True: \n    G.load_weights(PATH + f'/{VERSION}_Generator.h5')\n    D.load_weights(PATH + f'/{VERSION}_Discriminator.h5')\n\n# Optimizers\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5)\n\n@tf.function\ndef train_step(image, target, alpha):\n  \n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n\n      gen_output = G(image, training=True)\n      disc_real_output = D([image, target], training=True)\n      disc_fake_output = D([image, gen_output], training=True)\n      disc_loss = discriminator_loss(disc_real_output, disc_fake_output)\n\n    \n      gen_loss, dice_loss, disc_loss_gen = generator_loss(target, gen_output, disc_fake_output, alpha)\n      \n    \n      del gen_output, disc_real_output, disc_fake_output,image\n  generator_gradients = gen_tape.gradient(gen_loss, G.trainable_variables)\n  discriminator_gradients = disc_tape.gradient(disc_loss, D.trainable_variables)\n\n  generator_optimizer.apply_gradients(zip(generator_gradients, G.trainable_variables))\n  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, D.trainable_variables))\n      \n  return gen_loss, dice_loss, disc_loss_gen\n        \n@tf.function\ndef test_step(image, target, alpha):\n    gen_output = G(image, training=False)\n\n    disc_real_output = D([image, target], training=False)\n    disc_fake_output = D([image, gen_output], training=False)\n    disc_loss = discriminator_loss(disc_real_output, disc_fake_output)\n    \n    gen_loss, dice_loss, disc_loss_gen = generator_loss(target, gen_output, disc_fake_output, alpha)\n    del gen_output, disc_real_output, disc_fake_output,image    \n    return gen_loss, dice_loss, disc_loss_gen\n\ndef fit(train_gen, valid_gen, alpha, epochs, jump):\n    \n    if os.path.exists(PATH)==False:\n        os.mkdir(PATH)\n        \n    Nt = len(train_gen)\n    history = {'train': [], 'valid': []}\n    \n    #stats={'dice':[],'spec':[],'sen':[],'hau95':[]}\n    prev_loss = np.inf\n    \n    epoch_ugan_loss = tf.keras.metrics.Mean()\n    epoch_dice_loss = tf.keras.metrics.Mean()\n    epoch_disc_loss = tf.keras.metrics.Mean()\n    epoch_ugan_loss_val = tf.keras.metrics.Mean()\n    epoch_dice_loss_val = tf.keras.metrics.Mean()\n    epoch_disc_loss_val = tf.keras.metrics.Mean()\n    \n    vv_min = 2\n    \n    for e in range(epochs):\n        print('Epoch {}/{}'.format(e+1,epochs))\n        b = 0\n        \n#         x=(EXEC -1)*EPOCHS + e\n#         lrg=(math.exp(-x))*0.001 + 0.00003\n#         lrd=(math.exp(-x))*0.001 + 0.00003\n#         K.set_value(generator_optimizer.learning_rate, lrg)\n#         K.set_value(discriminator_optimizer.learning_rate, lrd)\n        \n        for i in tqdm(range(len(train_gen))):\n            _batch = train_gen[i]\n            Xb = _batch[0]\n            yb = _batch[1]\n            b += 1 \n            losses = train_step(Xb, yb, alpha)\n            epoch_ugan_loss.update_state(losses[0])\n            epoch_dice_loss.update_state(losses[1])\n            epoch_disc_loss.update_state(losses[2])\n\n            print('\\rBatch: {}/{} - loss: {:.4f} - dice_loss: {:.4f} - disc_loss: {:.4f}'\n                        .format(b, Nt, epoch_ugan_loss.result(), epoch_dice_loss.result(), epoch_disc_loss.result()))\n\n          \n        del Xb,yb,_batch   \n        history['train'].append([epoch_ugan_loss.result(), epoch_dice_loss.result(), epoch_disc_loss.result()])\n\n        \n        \n        for i in tqdm(range(len(valid_gen))):\n            _batch = valid_gen[i]\n            Xb = _batch[0]\n            yb = _batch[1]\n            losses_val = test_step(Xb, yb, alpha)\n            epoch_ugan_loss_val.update_state(losses_val[0])\n            epoch_dice_loss_val.update_state(losses_val[1])\n            epoch_disc_loss_val.update_state(losses_val[2])\n\n             \n        print('\\n               loss_val: {:.4f} - dice_loss_val: {:.4f} - disc_loss_val: {:.4f}'\n                     .format(epoch_ugan_loss_val.result(), epoch_dice_loss_val.result(), epoch_disc_loss_val.result()))\n        \n        history['valid'].append([epoch_ugan_loss_val.result(), epoch_dice_loss_val.result(), epoch_disc_loss_val.result()])\n#         print(history)\n        # save pred image at epoch e \n     \n        y_pred = G.predict(Xb)\n        y_true = np.argmax(yb, axis=-1)\n        y_pred = np.argmax(y_pred, axis=-1)\n        \n        canvas = np.zeros((512,512*3))\n        idx = np.random.randint(len(Xb))\n        \n        x = Xb[idx,:,:,0] \n        # print('image shape: ',x.shape)\n        canvas[0:512, 0:512] = (x - np.min(x))/(np.max(x)-np.min(x)+1e-6)\n        canvas[0:512, 512:2*512] = y_true[idx,:,:]/3\n        canvas[0:512, 2*512:3*512] = y_pred[idx,:,:]/3\n        \n        if jump:\n            n_e = e + (EXEC-1)*epochs\n        else:\n            n_e = e\n            \n        fname = (PATH + f'/{VERSION}'+'_pred@epoch_{:03d}.png').format(n_e+1)\n        mpim.imsave(fname, canvas, cmap='gray')\n        # save models\n        \n        try :\n            if epoch_dice_loss_val.result() <= vv_min:\n                G.save_weights(PATH + f'/{VERSION}_Generator.h5') \n                D.save_weights(PATH + f'/{VERSION}_Discriminator.h5')\n                vv_min = epoch_dice_loss_val.result()\n        except:\n            print('Models not saved')\n        \n        # resets losses states\n        epoch_v2v_loss.reset_states()\n        epoch_dice_loss.reset_states()\n        epoch_disc_loss.reset_states()\n        epoch_v2v_loss_val.reset_states()\n        epoch_dice_loss_val.reset_states()\n        epoch_disc_loss_val.reset_states()\n        \n        del(Xb, yb, _batch, canvas, y_pred, y_true, idx)\n       \n    return history","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:06.348570Z","iopub.status.busy":"2022-05-12T08:25:06.348301Z","iopub.status.idle":"2022-05-12T08:25:10.622702Z","shell.execute_reply":"2022-05-12T08:25:10.621971Z"},"id":"heeaG7mOkSAO","papermill":{"duration":4.334725,"end_time":"2022-05-12T08:25:10.624748","exception":false,"start_time":"2022-05-12T08:25:06.290023","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAIN ","metadata":{"id":"lDFy1TT-I45C","papermill":{"duration":0.060203,"end_time":"2022-05-12T08:25:10.742747","exception":false,"start_time":"2022-05-12T08:25:10.682544","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# create the training and validation sets\n\n\nBATCH_SIZE = 1\nALPHA = 5\nEPOCHS = 8\nNB_CLASSES = 2\nN_PATCHES = 1\nPATCH_SHAPE =(512,512,32)\n\n\nJUMP = False\npred_img = (PATH + f'/{VERSION}'+'_pred@epoch_{:03d}.png').format((EXEC-1)*EPOCHS) #0,8,16\nif os.path.exists(pred_img)==True:\n    JUMP = True\n\n\n\nct_list = sorted(glob.glob('../input/covid19-ct-scans/ct_scans/*.nii'))\nseg_list = sorted(glob.glob('../input/covid19-ct-scans/lung_and_infection_mask/*.nii'))\nseg_les_list = sorted(glob.glob('../input/covid19-ct-scans/infection_mask/*.nii'))\n\n\n\n\nNim = len(ct_list)\nprint(f'len dataset : {Nim}')\nidx = np.arange(Nim)\n\n# idxTrain, idxValid = train_test_split(idx, test_size=0.20) #0.20 a la place de 0.25\nidxTrain = [15, 3, 14, 16, 4, 2, 17, 6, 0, 1, 9, 8, 10, 11, 12]\nidxValid = [7, 18, 13, 19]\n\n\n\n\nprint(f'len train : {len(idxTrain)}, len test : {len(idxValid)}')\n\nsets = {'train': [], 'valid': []}\n\nfor i in idxTrain:\n    sets['train'].append([ct_list[i], seg_les_list[i], seg_list[i]])\nfor i in idxValid:\n    sets['valid'].append([ct_list[i], seg_les_list[i], seg_list[i]])\n      \ndel ct_list,seg_list,idx,Nim,idxTrain\n\ntrain_gen = DataGenerator(sets['train'], batch_size=BATCH_SIZE, patch_shape=PATCH_SHAPE, n_patches=N_PATCHES, n_classes=NB_CLASSES, augmentation=True)\nvalid_gen = DataGenerator(sets['valid'], batch_size=BATCH_SIZE, patch_shape=PATCH_SHAPE, n_patches=N_PATCHES, n_classes=NB_CLASSES, augmentation=True)\n\ndel sets","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:10.864829Z","iopub.status.busy":"2022-05-12T08:25:10.864565Z","iopub.status.idle":"2022-05-12T08:25:10.913582Z","shell.execute_reply":"2022-05-12T08:25:10.912720Z"},"id":"TJBarWbVGX8c","outputId":"b2c1762f-6194-4322-be8a-8d2e2c8ef64b","papermill":{"duration":0.111503,"end_time":"2022-05-12T08:25:10.915720","exception":false,"start_time":"2022-05-12T08:25:10.804217","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture cap --no-stderr\nh = fit(train_gen, valid_gen, ALPHA, EPOCHS, JUMP) ","metadata":{"execution":{"iopub.execute_input":"2022-05-12T08:25:11.314638Z","iopub.status.busy":"2022-05-12T08:25:11.314177Z","iopub.status.idle":"2022-05-12T13:54:04.013470Z","shell.execute_reply":"2022-05-12T13:54:04.012620Z"},"id":"flG5HOEntWp4","papermill":{"duration":19732.760321,"end_time":"2022-05-12T13:54:04.015736","exception":false,"start_time":"2022-05-12T08:25:11.255415","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(PATH + f'/{VERSION}_fit_output_{EXEC}.txt', 'w') as f:\n    f.write(cap.stdout)","metadata":{"execution":{"iopub.execute_input":"2022-05-12T13:54:04.559032Z","iopub.status.busy":"2022-05-12T13:54:04.558751Z","iopub.status.idle":"2022-05-12T13:54:04.565048Z","shell.execute_reply":"2022-05-12T13:54:04.564224Z"},"papermill":{"duration":0.280409,"end_time":"2022-05-12T13:54:04.567106","exception":false,"start_time":"2022-05-12T13:54:04.286697","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture cap_h --no-stderr\nprint(h)","metadata":{"execution":{"iopub.execute_input":"2022-05-12T13:54:05.110091Z","iopub.status.busy":"2022-05-12T13:54:05.109817Z","iopub.status.idle":"2022-05-12T13:54:05.121170Z","shell.execute_reply":"2022-05-12T13:54:05.120507Z"},"papermill":{"duration":0.286475,"end_time":"2022-05-12T13:54:05.122852","exception":false,"start_time":"2022-05-12T13:54:04.836377","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(PATH + f'/{VERSION}_h_{EXEC}.txt', 'w') as f:\n    f.write(cap_h.stdout)","metadata":{"execution":{"iopub.execute_input":"2022-05-12T13:54:05.676250Z","iopub.status.busy":"2022-05-12T13:54:05.675704Z","iopub.status.idle":"2022-05-12T13:54:05.680929Z","shell.execute_reply":"2022-05-12T13:54:05.680236Z"},"papermill":{"duration":0.279585,"end_time":"2022-05-12T13:54:05.682758","exception":false,"start_time":"2022-05-12T13:54:05.403173","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#last loop for metrics\nfrom sklearn.metrics import precision_score\n#Importing tqdm function of tqdm module \nfrom tqdm import tqdm  \nfrom time import sleep \n\n\nG = Generator()\n\nG.load_weights(PATH + f'/{VERSION}_Generator.h5')\n\nstats={'dice':[],'spec':[],'sen':[]}\ni=0\nlist_id = []\n\nfor bb in tqdm(range(len(valid_gen))):\n    for k in range(BATCH_SIZE):\n        for n in range(N_PATCHES*32):\n            list_id.append(idxValid[i])\n        i=i+1\n\ni=0\nfor Xb,yb in tqdm(valid_gen):\n    for k in range(len(Xb)):\n#         print(len(Xb))\n#         print(i)\n        segG = G.predict(Xb)[k,:]\n        segTr = yb[k,:]\n        case = list_id[i]\n#         case = 0\n        i=i+1\n        segG_all = np.argmax(segG, axis=-1)\n        segTr_all = np.argmax(segTr, axis=-1)\n#         print(np.min(segG_all),np.max(segG_all))\n        dsc = dice_coef(segG_all>0,segTr_all>0)\n\n        spec = specificity(segG_all>0,segTr_all>0)\n\n        sen = sensitivity(segG_all>0,segTr_all>0)\n\n#         hau= Hausdorff_distance(segG_all>0,segTr_all>0)\n\n#         stats['dice'].append({'caseID':int(case),'value':dsc})\n        stats['dice'].append({'caseID':int(case),'value':dsc})\n        stats['spec'].append({'caseID':int(case),'value':spec})\n        stats['sen'].append({'caseID':int(case),'value':sen})\n#         stats['hau95'].append({'caseID':int(case),'value':hau})\n\n        del segG,segG_all,segTr,segTr_all\n\nwith open(PATH + f'/{VERSION}_stats_{EXEC}.json', 'w') as f:\n          json.dump(stats, f, indent=2)\n          print(\"stats saved.\")","metadata":{"execution":{"iopub.execute_input":"2022-05-12T13:54:06.223004Z","iopub.status.busy":"2022-05-12T13:54:06.222744Z","iopub.status.idle":"2022-05-12T14:06:32.402909Z","shell.execute_reply":"2022-05-12T14:06:32.401918Z"},"id":"8yauX0Lnt1G1","papermill":{"duration":746.711467,"end_time":"2022-05-12T14:06:32.663580","exception":false,"start_time":"2022-05-12T13:54:05.952113","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture cap_metrics --no-stderr\ndice = []\nsen = []\nspec = []\nhau = []\n\nimport numpy as np\n\n# print (stats['dice'][0]['WT'])\nfor k in range(len(valid_gen)*BATCH_SIZE*N_PATCHES*32):\n    dice.append(stats['dice'][k]['value'])\n    sen.append(stats['sen'][k]['value'])\n    spec.append(stats['spec'][k]['value'])\n#     hau.append(stats['hau95'][k]['value'])\n\nprint(f'DSC: {np.mean(dice)}')\nprint(f'SEN: {np.mean(sen)}')\nprint(f'SPE: {np.mean(spec)}')\n# print(f'H95: {np.mean(hau)}')\n","metadata":{"execution":{"iopub.execute_input":"2022-05-12T14:06:33.211499Z","iopub.status.busy":"2022-05-12T14:06:33.211202Z","iopub.status.idle":"2022-05-12T14:06:33.221722Z","shell.execute_reply":"2022-05-12T14:06:33.221027Z"},"id":"qRnFncxZwJkR","papermill":{"duration":0.287338,"end_time":"2022-05-12T14:06:33.223387","exception":false,"start_time":"2022-05-12T14:06:32.936049","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(PATH + f'/{VERSION}_metrics_{EXEC}.txt', 'w') as f:\n    f.write(cap_metrics.stdout)","metadata":{"execution":{"iopub.execute_input":"2022-05-12T14:06:33.773058Z","iopub.status.busy":"2022-05-12T14:06:33.772364Z","iopub.status.idle":"2022-05-12T14:06:33.777083Z","shell.execute_reply":"2022-05-12T14:06:33.776232Z"},"papermill":{"duration":0.285484,"end_time":"2022-05-12T14:06:33.778866","exception":false,"start_time":"2022-05-12T14:06:33.493382","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! zip -r './results.zip' {PATH+'/*'}","metadata":{"execution":{"iopub.execute_input":"2022-05-12T14:06:34.326790Z","iopub.status.busy":"2022-05-12T14:06:34.326194Z","iopub.status.idle":"2022-05-12T14:06:38.689058Z","shell.execute_reply":"2022-05-12T14:06:38.687857Z"},"papermill":{"duration":4.63802,"end_time":"2022-05-12T14:06:38.691393","exception":false,"start_time":"2022-05-12T14:06:34.053373","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./results.zip')\n# then in colab : !wget \"https://....kaggle.net/...../results.zip\"","metadata":{"execution":{"iopub.execute_input":"2022-05-12T14:06:39.279714Z","iopub.status.busy":"2022-05-12T14:06:39.278863Z","iopub.status.idle":"2022-05-12T14:06:39.285191Z","shell.execute_reply":"2022-05-12T14:06:39.284485Z"},"papermill":{"duration":0.285705,"end_time":"2022-05-12T14:06:39.286991","exception":false,"start_time":"2022-05-12T14:06:39.001286","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}